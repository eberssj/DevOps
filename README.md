Guia de Testes UnitÃ¡rios no DevOps ğŸ§ª
1. IntroduÃ§Ã£o aos Testes UnitÃ¡rios ğŸŒŸ
Testes unitÃ¡rios sÃ£o verificaÃ§Ãµes automatizadas que validam o comportamento de unidades individuais de cÃ³digo, como funÃ§Ãµes, mÃ©todos ou componentes, de forma isolada. No contexto de DevOps, eles sÃ£o fundamentais para:

Confiabilidade âœ…: Identificam erros rapidamente durante o desenvolvimento, reduzindo bugs em produÃ§Ã£o.
IntegraÃ§Ã£o ContÃ­nua ğŸ”„: Garantem merges seguros nas branches develop e main, facilitando a entrega contÃ­nua.
ReduÃ§Ã£o de Riscos ğŸ›¡ï¸: Validam regras de negÃ³cio antes do deploy, assegurando qualidade.

No projeto, os testes unitÃ¡rios cobrem o backend (rotas FastAPI) e o frontend (componentes React/TSX), usando mocks para simular dependÃªncias como o banco de dados PostgreSQL. ğŸ—„ï¸
2. IntegraÃ§Ã£o com Gitflow ğŸŒ³
O projeto adota o Gitflow com as seguintes branches:

main: CÃ³digo estÃ¡vel, consolidado ao final de cada sprint. ğŸ
develop: IntegraÃ§Ã£o e testes de funcionalidades desenvolvidas. ğŸ”§
Branches de atividade: Nomeadas como [SCRUM-<nÃºmero>] feat/fix: <mensagem>, criadas para cada tarefa. ğŸ“

Fluxo de Testes no Gitflow

CriaÃ§Ã£o da branch de atividade:
Criada a partir de develop, e.g., [SCRUM-1] feat: criar rota de estaÃ§Ã£o.
O desenvolvedor implementa a funcionalidade e escreve testes unitÃ¡rios correspondentes.
Testes sÃ£o executados localmente para validar os critÃ©rios de aceitaÃ§Ã£o. âœ…


Merge para develop:
A branch Ã© enviada via merge request.
O pipeline de CI/CD executa os testes automaticamente, verificando cobertura (mÃ­nimo 80%, exigÃªncia do QA). ğŸš€
Se os testes falharem, o merge Ã© bloqueado atÃ© correÃ§Ãµes. ğŸš«


ConsolidaÃ§Ã£o na main:
No final da sprint, develop Ã© mergeada em main.
Testes sÃ£o reexecutados para garantir integridade antes do deploy. ğŸ› ï¸



Regra de QA ğŸ“‹: O time de QA exige cobertura mÃ­nima de 80% nos testes unitÃ¡rios, validada pelo pipeline de CI/CD, para aprovar o deploy.
3. Testes UnitÃ¡rios no Backend (FastAPI) ğŸ
Os testes do backend utilizam pytest e pytest-asyncio, com um banco de dados simulado (SQLite em memÃ³ria) via SQLAlchemy. A configuraÃ§Ã£o estÃ¡ em tests/conftest.py, e os testes em arquivos como tests/test_estacoes.py.
PrÃ©-requisitos

DependÃªncias:pip install pytest==7.4.0 pytest-asyncio==0.21.0 httpx==0.24.0 sqlalchemy==2.0.0


Ambiente: Arquivo tests/conftest.py configurado com fixtures db_session e client.
Sincronia: Testes (e.g., tests/test_estacoes.py) devem corresponder Ã s funcionalidades (e.g., app/routers/estacoes.py).

Comandos para Testes

Rodar todos os testes:pytest tests/ -v

SaÃ­da: Lista de testes com status (PASSED, FAILED) e tempo. Exemplo:tests/test_estacoes.py::test_create_estacao_success PASSED [100%]


Rodar teste especÃ­fico:pytest tests/test_estacoes.py::test_create_estacao_success -v


Verificar cobertura:pytest --cov=app --cov-report=term tests/



PadrÃ£o de Escrita
Usamos o padrÃ£o Given-When-Then:

Given: Configura o estado inicial (mocks, dados simulados).
When: Executa a aÃ§Ã£o testada (e.g., requisiÃ§Ã£o HTTP).
Then: Verifica o resultado (e.g., status code, dados retornados).

Estrutura de Arquivos

Testes em tests/ (e.g., tests/test_estacoes.py).
NomeaÃ§Ã£o descritiva, sem seguir a hierarquia do cÃ³digo-fonte.

Exemplo de Teste Aceito (Backend)
Teste para a rota POST /estacoes/ que cria uma estaÃ§Ã£o com dados vÃ¡lidos:
def test_create_estacao_success(client, db_session):
    # Given: Dados vÃ¡lidos para criar uma estaÃ§Ã£o
    estacao_data = {"nome": "EstaÃ§Ã£o Teste", "latitude": -23.5, "longitude": -46.6}
    # When: Faz a requisiÃ§Ã£o POST
    response = client.post("/estacoes/", json=estacao_data)
    # Then: Verifica status 201 e dados retornados
    assert response.status_code == 201
    assert response.json()["nome"] == "EstaÃ§Ã£o Teste"

SaÃ­da: tests/test_estacoes.py::test_create_estacao_success PASSEDImagem: Adicione a captura de tela localmente com:
![Teste Aceito - Backend](./images/teste_aceito_backend.png)

Exemplo de Teste Rejeitado (Backend)
Teste para a rota POST /estacoes/ com latitude invÃ¡lida:
def test_create_estacao_invalid_latitude(client):
    # Given: Dados com latitude fora do intervalo permitido
    estacao_data = {"nome": "EstaÃ§Ã£o Teste", "latitude": -100, "longitude": -46.6}
    # When: Faz a requisiÃ§Ã£o POST
    response = client.post("/estacoes/", json=estacao_data)
    # Then: Verifica erro 422 (validaÃ§Ã£o)
    assert response.status_code == 422
    assert "latitude" in response.json()["detail"][0]["loc"]

SaÃ­da: tests/test_estacoes.py::test_create_estacao_invalid_latitude FAILED (se a validaÃ§Ã£o nÃ£o for implementada corretamente).Imagem: Adicione a captura de tela localmente com:
![Teste Rejeitado - Backend](./images/teste_rejeitado_backend.png)

4. Testes UnitÃ¡rios no Frontend (React/TSX) âš›ï¸
Os testes do frontend usam Jest com React Testing Library para testar componentes como BotaoCTA. ConfiguraÃ§Ã£o em tests/setupTests.ts e jest.config.js, com testes em tests/test_BotaoCTA.test.tsx.
PrÃ©-requisitos

DependÃªncias:npm install --save-dev @testing-library/react@14.0.0 @testing-library/jest-dom@5.16.0 jest@29.7.0 ts-jest@29.1.0 @types/jest@29.5.0


Ambiente: ConfiguraÃ§Ã£o em jest.config.js e tests/setupTests.ts.
Sincronia: Testes (e.g., tests/test_BotaoCTA.test.tsx) correspondem aos componentes (e.g., src/components/BotaoCTA.tsx).

Comandos para Testes

Rodar todos os testes:npm run test

SaÃ­da: Resumo com status e tempo. Exemplo:PASS  tests/test_BotaoCTA.test.tsx
  BotaoCTA
    âœ“ deve renderizar um botÃ£o com texto e disparar onClick (5ms)


Rodar teste especÃ­fico:npm run test tests/test_BotaoCTA.test.tsx


Verificar cobertura:npm run test -- --coverage



PadrÃ£o de Escrita
Usamos o padrÃ£o Setup-Action-Expect:

Setup: Renderiza o componente e configura o estado.
Action: Simula interaÃ§Ãµes (e.g., cliques).
Expect: Verifica o comportamento ou estado.

Estrutura de Arquivos

Testes em tests/ (e.g., tests/test_BotaoCTA.test.tsx).
Nomeados para refletir o componente testado, com extensÃ£o .test.tsx.

Exemplo de Teste Aceito (Frontend)
Teste para o componente BotaoCTA:
import { render, fireEvent, screen } from '@testing-library/react';
import BotaoCTA from '../src/components/BotaoCTA';

test('deve renderizar um botÃ£o com texto e disparar onClick', () => {
  // Setup: Renderiza o componente
  const handleClick = jest.fn();
  render(<BotaoCTA texto="Clique Aqui" onClick={handleClick} />);
  // Action: Simula clique no botÃ£o
  fireEvent.click(screen.getByText('Clique Aqui'));
  // Expect: Verifica se a funÃ§Ã£o foi chamada
  expect(handleClick).toHaveBeenCalledTimes(1);
});

SaÃ­da: PASS tests/test_BotaoCTA.test.tsxImagem: Adicione a captura de tela localmente com:
![Teste Aceito - Frontend](./images/teste_aceito_frontend.png)

Exemplo de Teste Rejeitado (Frontend)
Teste para o componente BotaoCTA com texto incorreto:
import { render, screen } from '@testing-library/react';
import BotaoCTA from '../src/components/BotaoCTA';

test('deve renderizar o texto correto no botÃ£o', () => {
  // Setup: Renderiza o componente
  render(<BotaoCTA texto="Clique Aqui" onClick={() => {}} />);
  // Expect: Verifica texto incorreto
  expect(screen.getByText('Enviar')).toBeInTheDocument();
});

SaÃ­da: FAIL tests/test_BotaoCTA.test.tsx (texto "Enviar" nÃ£o encontrado).Imagem: Adicione a captura de tela localmente com:
![Teste Rejeitado - Frontend](./images/teste_rejeitado_frontend.png)

5. Checklist de Qualidade ğŸ“
Antes de abrir um merge request:

 Todos os testes unitÃ¡rios passam localmente. âœ…
 Novas funcionalidades tÃªm testes para fluxos principais e de erro. ğŸ› ï¸
 CritÃ©rios de aceitaÃ§Ã£o (Jira) estÃ£o cobertos. ğŸ“‹
 Pipeline de CI/CD executa testes automaticamente. ğŸš€
 Cobertura de testes â‰¥ 80% (exigÃªncia do QA para deploy). ğŸ“Š

6. Resumo do Workflow de Testes ğŸ› ï¸
Como Ã© Testado? ğŸ§ª
Os testes unitÃ¡rios validam unidades especÃ­ficas do sistema:

Backend (FastAPI):

Rotas testadas: FunÃ§Ãµes como create_estacao, update_estacao, read_estacoes, delete_estacao.
Ferramentas: pytest, pytest-asyncio, FastAPI TestClient (simula requisiÃ§Ãµes HTTP), unittest.mock (isola dependÃªncias como Session do SQLAlchemy).
Mocks: Simulam o banco de dados (SQLite em memÃ³ria) e retornos de modelos (e.g., Estacao, Parametro).
CenÃ¡rios testados:
Sucesso: CriaÃ§Ã£o de estaÃ§Ã£o com dados vÃ¡lidos, retorno de status 201, e validaÃ§Ã£o dos dados retornados.
Erro: Casos como estaÃ§Ã£o inexistente (404), dados invÃ¡lidos (422), ou erros internos (500).
ValidaÃ§Ãµes: Formato de CEP, intervalos de latitude/longitude, e associaÃ§Ãµes com sensores.


Cobertura: Usamos pytest-cov para garantir 100% de cobertura, incluindo ramificaÃ§Ãµes condicionais (e.g., tratamento de exceÃ§Ãµes). A exigÃªncia mÃ­nima do QA Ã© 80%.
Exemplo: Um teste para POST /estacoes/ verifica a criaÃ§Ã£o de uma estaÃ§Ã£o com sensores associados, mockando a sessÃ£o do banco e validando o JSON retornado.


Frontend (React/TSX):

Componentes testados: Componentes como BotaoCTA, verificando renderizaÃ§Ã£o e interaÃ§Ãµes.
Ferramentas: Jest, React Testing Library, ts-jest (suporte a TypeScript).
Mocks: Simulam eventos do usuÃ¡rio (e.g., cliques) e estados do componente.
CenÃ¡rios testados:
Sucesso: RenderizaÃ§Ã£o correta de texto e comportamento de cliques.
Erro: Falha na renderizaÃ§Ã£o de elementos ou comportamento incorreto.


Cobertura: RelatÃ³rios de cobertura via npm run test -- --coverage, visando 100% (mÃ­nimo 80% pelo QA).
Exemplo: Um teste para BotaoCTA verifica se o botÃ£o renderiza o texto correto e dispara a funÃ§Ã£o onClick.



Por Quem Ã© Testado? ğŸ‘¥

Desenvolvedores:
Escrevem e executam testes nas branches de atividade (e.g., feature/add-estacao-route).
Garantem 100% de cobertura localmente antes de abrir um PR, usando pytest (backend) ou npm run test (frontend).
Exemplo: Um desenvolvedor implementa create_estacao e escreve test_create_estacao em tests/test_estacoes.py.


Revisores:
Durante o PR para develop, outro desenvolvedor revisa o cÃ³digo e os testes, verificando:
Cobertura de cenÃ¡rios (sucesso e erro).
Conformidade com convenÃ§Ãµes (e.g., sufixo _test.py ou .test.tsx).
Cobertura mÃ­nima de 80% (exigÃªncia do QA).




Time de QA:
Define a regra de cobertura mÃ­nima (80%) e valida os relatÃ³rios de cobertura no pipeline.
Revisa critÃ©rios de aceitaÃ§Ã£o (Jira) para garantir que os testes os atendem.


DevOps:
Configura e mantÃ©m o pipeline de CI/CD (e.g., GitHub Actions, Jenkins) para executar testes automaticamente.
Garante que o pipeline bloqueia merges se a cobertura for < 80% ou se testes falharem.


AutomaÃ§Ã£o: O pipeline executa testes em cada push para develop e main, garantindo validaÃ§Ã£o contÃ­nua.

Quando Ã© Testado? ğŸ•’

Durante o desenvolvimento:
Localmente, nas branches de atividade, enquanto o desenvolvedor implementa a funcionalidade.
Exemplo: Executa pytest tests/test_estacoes.py ou npm run test tests/test_BotaoCTA.test.tsx vÃ¡rias vezes ao dia.


Antes do merge para develop:
Ao abrir um PR, o pipeline de CI/CD executa todos os testes automaticamente.
Gatilho: Cada push para o PR ou branch develop.
A cobertura Ã© verificada (mÃ­nimo 80%), e o merge Ã© bloqueado se os testes falharem.


Antes do merge para main:
No final da sprint (a cada 2-4 semanas), quando develop Ã© mergeada em main.
O pipeline reexecuta todos os testes para garantir que o cÃ³digo consolidado estÃ¡ correto.


FrequÃªncia:
ContÃ­nua: Testes locais durante o desenvolvimento (vÃ¡rias vezes ao dia).
Por evento: Em cada push/PR para develop (diÃ¡rio ou vÃ¡rias vezes por sprint).
Sazonal: No merge para main (final da sprint, geralmente quinzenal ou mensal).



